{"cells":[{"cell_type":"markdown","metadata":{"id":"9_HjQjUnhVVR"},"source":["<center>\n","    <h1>Comparison performance of different models</h1>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"ovS9CabJhVVV"},"source":["In this notebook, we will train different models on a small part of the dataset in order to compare them and check which best suits for our problem."]},{"cell_type":"markdown","metadata":{"id":"rJXLE8e4hVVV"},"source":["<table align=\"left\">\n","    <td>\n","        <a href=\"https://colab.research.google.com/github/dailoht/Epitech_Zoidberg2.0/blob/main/notebooks/models/pab-model_comparison.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","    </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"GR4NF354hVVW"},"source":["# 1. Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ep1GVKzhVVW","outputId":"e3ff5d07-d962-40c1-bc69-07262ba5d93b"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-04-18 09:56:42.017747: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["We're running localy\n"]}],"source":["# Import base librairies\n","import sys\n","import os\n","from pathlib import Path\n","import time\n","\n","# Import scientific librairies\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Import Tensorflow and Keras\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Import scikit-learn\n","from sklearn.utils import class_weight\n","\n","# Check running environment\n","try:\n","    import google.colab\n","    IN_COLAB=True\n","except:\n","    IN_COLAB=False\n","\n","# Add project directory to kernel paths\n","if IN_COLAB:\n","    print(\"We're running on Colab\")\n","    !git clone https://github.com/dailoht/Epitech_Zoidberg2.0.git\n","    sys.path.append('./Epitech_Zoidberg2.0')\n","else:\n","    print(\"We're running localy\")\n","    sys.path.append('../..')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"1AzhPlgnhVVX","outputId":"54cee821-a498-4d83-f733-1e2b42a1b6ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected distribution strategy:                     _DefaultDistributionStrategy\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-18 09:56:55.727884: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["# Import custom functions\n","from src.visualization.plot_lib import default_viz\n","from src.data.file_manager import FileManager\n","from src.data.tf_utils import load_image_dataset_from_tfrecord, define_distribute_strategy\n","from src.data.evaluation import Evaluation\n","\n","zoidbergManager = FileManager()\n","strategy = define_distribute_strategy()\n","evaluation = Evaluation()\n","\n","# Set default graphics visualization\n","%matplotlib inline\n","default_viz()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPCOdNLAhVVY"},"outputs":[],"source":["# set random seed for keras, numpy, tensorflow, and the 'random' module\n","SEED = 42\n","tf.keras.utils.set_random_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)"]},{"cell_type":"markdown","metadata":{"id":"FomE23rKhVVY"},"source":["# 2. Loading dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRVsCBmAhVVZ"},"outputs":[],"source":["BATCH_SIZE = 32\n","SMALL_TRAIN_SPLIT = 0.1\n","SMALL_VAL_SPLIT = 0.15\n","class_names = ['batceria', 'normal', 'virus']"]},{"cell_type":"markdown","metadata":{"id":"L_7VF9HkhVVZ"},"source":["First, let's load the train and val datasets :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1Fqk3KjhVVZ"},"outputs":[],"source":["processed_dir_path = zoidbergManager.data_dir / 'processed'\n","\n","train_path = str(processed_dir_path / 'train_512x512_rgb_ds.tfrecord')\n","val_path = str(processed_dir_path / 'val_512x512_rgb_ds.tfrecord')\n","\n","train_ds = load_image_dataset_from_tfrecord(train_path)\n","val_ds = load_image_dataset_from_tfrecord(val_path)"]},{"cell_type":"markdown","metadata":{"id":"0k7N66K2hVVa"},"source":["Then, we extract a small part of each datasets to train each models on a small dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-Nxrf_LhVVa","outputId":"1ef7bd50-f58b-45c3-ed93-2fdd38456932"},"outputs":[{"name":"stdout","output_type":"stream","text":["In training dataset, there are :\n","  - 221 files for class batceria\n","  - 121 files for class normal\n","  - 126 files for class virus\n","\n","In val dataset, there are :\n","  - 20 files for class batceria\n","  - 11 files for class normal\n","  - 12 files for class virus\n"]}],"source":["num_train_img = train_ds.reduce(0, lambda x, _: x + 1).numpy()\n","num_val_img = val_ds.reduce(0, lambda x, _: x + 1).numpy()\n","\n","# Shuffle data\n","train_ds = train_ds.shuffle(buffer_size=num_train_img, seed=42)\n","val_ds = val_ds.shuffle(buffer_size=num_val_img, seed=42)\n","\n","# Extract a sample\n","small_train_size = int(num_train_img * SMALL_TRAIN_SPLIT)\n","small_val_size = int(num_val_img * SMALL_VAL_SPLIT)\n","\n","small_train_ds = train_ds.take(small_train_size)\n","small_val_ds = val_ds.take(small_val_size)\n","\n","def count_img_by_class(dataset, class_names=class_names):\n","    num_img_by_classes = {name:0 for name in class_names}\n","    for images, labels in dataset:\n","        idx_label = np.nonzero(labels.numpy())[0][0]\n","        for idx, name in enumerate(class_names):\n","            if idx_label == idx:\n","                num_img_by_classes[name] += 1\n","    return num_img_by_classes\n","\n","print(\"In training dataset, there are :\")\n","for class_name, num_img in count_img_by_class(small_train_ds).items():\n","    print(f\"  - {num_img} files for class {class_name}\")    \n","print(\"\\nIn val dataset, there are :\")\n","for class_name, num_img in count_img_by_class(small_val_ds).items():\n","    print(f\"  - {num_img} files for class {class_name}\")"]},{"cell_type":"markdown","metadata":{"id":"nf4nlfGshVVb"},"source":["Finally, we also need to perform some actions on datasets before they can be used : \n","- batching images\n","- prefetching images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tePgFGYZhVVb"},"outputs":[],"source":["# Batch & prefecth data to improve computation time\n","small_train_ds = small_train_ds.batch(BATCH_SIZE).prefetch(\n","    buffer_size=tf.data.AUTOTUNE)\n","\n","small_val_ds = small_val_ds.batch(BATCH_SIZE).prefetch(\n","    buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{"id":"OvzPxqqrhVVb"},"source":["# 3. Training models"]},{"cell_type":"markdown","metadata":{"id":"zUXib_s1hVVb"},"source":["Let's now train models on this small dataset. We set useful variables below.  \n","\n","\n","\n","⚠️⚠️⚠️ WARNING : Depending on your hardware, training cells can be computationally expensive and take a really long time to run them !!!  \n","That's why each of these cells are wrapped in a if condition (see `TRAIN_*MODEL*` booleans below)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjPDpNmLhVVc"},"outputs":[],"source":["EPOCHS = 30\n","LEARNING_RATE = 0.0001\n","OPTIMIZER = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","LOSS_FUNCTION = 'categorical_crossentropy'\n","\n","TRAIN_VGG16 = False\n","TRAIN_VGG19 = False\n","TRAIN_RESNET50 = False\n","TRAIN_DENSENET101 = False\n","TRAIN_XCEPTION = False\n","TRAIN_EFFICIENTNETB0 = False"]},{"cell_type":"markdown","metadata":{"id":"LnlgrZcQhVVc"},"source":["We define also 2 callbacks : \n","- `checkpoint_cb` : save model at each epoch (only save best weight).\n","- `earlystopping_cb` : stop training if model does not progress. It is faster and helps against overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QezE9-_EhVVc"},"outputs":[],"source":["def checkpoint_cb(model):\n","    checkpoint_dir = zoidbergManager.model_dir / 'checkpoints'\n","    checkpoint_filepath = checkpoint_dir / f'ckpt_smallds_{model.name}.h5'\n","    ckpt_cb = keras.callbacks.ModelCheckpoint(\n","        filepath=checkpoint_filepath,\n","        monitor='val_Matthews_coef',\n","        mode='max',\n","        save_best_only=True\n","    )\n","    return ckpt_cb\n","\n","earlystopping_cb = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=3\n",")"]},{"cell_type":"markdown","metadata":{"id":"-BIMS_8rhVVc"},"source":["Next, we compute class weights to prevent imbalanced classes (as we saw when we analyzed data) : "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmdrfrxghVVd","outputId":"81e939c7-2bfe-4a46-a56c-9ea8a88a2ec1"},"outputs":[{"name":"stdout","output_type":"stream","text":["class batceria => weight : 0.693458\n","class normal => weight : 1.248335\n","class virus => weight : 1.321207\n"]}],"source":["y_train_iterator = train_ds.map(lambda x, y: y).as_numpy_iterator()\n","y_train = np.argmax(np.fromiter(y_train_iterator, dtype=np.dtype((float, 3))), axis=1)\n","\n","class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n","class_weights\n","dic_class_weights = {}\n","for idx, weight in enumerate(class_weights):\n","    dic_class_weights[idx] = weight\n","    print(f'class {class_names[idx]} => weight : {weight:2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSi-ELoOhVVd"},"outputs":[],"source":["def train_model(model):\n","    start_time = time.time()\n","    history = model.fit(small_train_ds,\n","                        validation_data=small_val_ds,\n","                        epochs=EPOCHS,\n","                        steps_per_epoch=(small_train_size // BATCH_SIZE + 1),\n","                        class_weight=dic_class_weights,\n","                        callbacks=[checkpoint_cb(model), earlystopping_cb],\n","                        )\n","    training_time = time.time() - start_time\n","    return history, training_time"]},{"cell_type":"markdown","metadata":{"id":"cCiLE3BJhVVd"},"source":["## 3.1 VGG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NE5g5a9khVVd","outputId":"3754b174-0d2b-4c1e-d2e3-17cc40d5792d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resize (Resizing)           (None, 224, 224, 3)       0         \n","                                                                 \n"," rescale (Rescaling)         (None, 224, 224, 3)       0         \n","                                                                 \n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fully_conn1 (Dense)         (None, 1024)              25691136  \n","                                                                 \n"," fully_conn2 (Dense)         (None, 512)               524800    \n","                                                                 \n"," out_softmax (Dense)         (None, 3)                 1539      \n","                                                                 \n","=================================================================\n","Total params: 40,932,163\n","Trainable params: 26,217,475\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["def make_vgg16():\n","    base_vgg16 = tf.keras.applications.VGG16(weights='imagenet', input_shape=(224,224,3), include_top=False)\n","    for layer in base_vgg16.layers:\n","        layer.trainable = False\n","    \n","    vgg16 = tf.keras.Sequential([\n","        keras.layers.InputLayer(input_shape=(512,512,3), name='input'),\n","        keras.layers.Resizing(224, 224, interpolation=\"bilinear\", name='resize'),\n","        keras.layers.Rescaling(scale=1./255., name='rescale'),\n","        base_vgg16,\n","        keras.layers.Flatten(name='flatten'),\n","        keras.layers.Dense(1024, activation='relu', name='fully_conn1'),\n","        keras.layers.Dense(512, activation='relu', name='fully_conn2'),\n","        keras.layers.Dense(3, activation='softmax', name='out_softmax'),\n","    ], name = 'vgg16')\n","\n","    vgg16.compile(optimizer=OPTIMIZER,\n","                  loss=LOSS_FUNCTION,\n","                  metrics=evaluation.get_training_metrics()\n","                 )\n","    return vgg16\n","    \n","with strategy.scope():\n","    vgg16 = make_vgg16()\n","\n","vgg16.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"ZZs5AHk7hVVe"},"outputs":[],"source":["if TRAIN_VGG16:\n","    vgg16_history, vgg16_time = train_model(vgg16)"]},{"cell_type":"markdown","metadata":{"id":"ghcM_yeEhVVe"},"source":["## 3.2 ResNet"]},{"cell_type":"markdown","metadata":{"id":"rYGm2RmkhVVe"},"source":["## 3.3 DenseNet"]},{"cell_type":"markdown","metadata":{"id":"413g_qTrhVVe"},"source":["## 3.4 Xception"]},{"cell_type":"markdown","metadata":{"id":"7RfpvOgthVVe"},"source":["## 3.5 EfficientNet"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmr3XXjxhVVe","executionInfo":{"status":"ok","timestamp":1681807389890,"user_tz":-120,"elapsed":213,"user":{"displayName":"Pierre-Alexandre Bolteau","userId":"17404311271627354485"}},"outputId":"9440e717-c931-4f1d-d4d0-c527bb88a2a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 16\n","drwxr-xr-x 1 root root 4096 Apr 14 13:35 .\n","drwxr-xr-x 1 root root 4096 Apr 18 08:39 ..\n","drwxr-xr-x 4 root root 4096 Apr 14 13:34 .config\n","drwxr-xr-x 1 root root 4096 Apr 14 13:35 sample_data\n"]}],"source":["!ls -al"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}